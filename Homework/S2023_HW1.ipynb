{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 1: Coding Part\n",
        "Due: Feb 15, 2021 at 11:59 pm\n",
        "\n",
        "Submit through Sakai"
      ],
      "metadata": {
        "id": "bpOvvdHwuC80"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trB1uensah2P"
      },
      "source": [
        "# Classification of MNIST\n",
        "\n",
        "MNIST is a dataset of images, consisting of handwritten numbers 0-9 widely used as a benchmark in machine learning. While the dataset is very simple, it is still in seminal papers to demonstrate proof of concept (i.e. [Dynamic Routing](https://arxiv.org/pdf/1710.09829.pdf)). Below we load some sample images of handwritten digits for you.\n",
        "\n",
        "Benchmark datasets are very useful, to note a couple other widely used benchmarks: [SVHN](http://ufldl.stanford.edu/housenumbers/) (Street View House Numbers), [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) (Like MNIST, but more fashion), [CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html) (10 and 100 different objects), and [ImageNet](http://www.image-net.org/) (very large real world image dataset).\n",
        "\n",
        "We load up the MNIST dataset below. Eeach image in the MNIST set is 28x28 pixels and is frequently \"vectorized\" into a vector that contains 784 entries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7-YVby7ah2S"
      },
      "source": [
        "# Import datasets (just run this block)\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import fetch_openml\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# might take a few minutes\n",
        "digit, target = fetch_openml(\n",
        "    \"mnist_784\", return_X_y=True, as_frame=False)\n",
        "digit = (digit/255.0).reshape(-1,28,28)\n",
        "target = target.astype(int)\n",
        "for index, (image, label) in enumerate(list(zip(digit, target))[12:22]):\n",
        "    plt.subplot(1, 10, index + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r)\n",
        "    plt.title('%i' % label)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaCC1cCQah2X"
      },
      "source": [
        "# Part I\n",
        "\n",
        "In this homework, you will develop software to classify images of two unique hand-written digits of your choice. That is, you will set aside 300 examples of one hand-written digit, and 300 examples of another hand-written digit, and will develop a computational process to automatically categorize each digit type (i.e., for future example hand-written digits that you may encounter).\n",
        "\n",
        "We start by choosing the digits and selecting 300 samples for each of them. We will then create our training and testing datasets by splitting these sample groups, using `sklearn.model_selection.train_test_split`, a convenient function. We want to save 10% of the data for testing our developed algorithm. Remember that we want to save our test sets separately, so we can fairly evaluate how well our new algorithms classify on new, *unseen* image data.\n",
        "\n",
        "`X_test` and `y_test` should be used to evaluate the performance of the classifier you build at the end, where the former is the image dataset itself, while the latter are the associated labels for each image. Moving forward here, please just work with `X_train` and `y_train`, which are the associated dataset and labels that you can use for algorithm development.\n",
        "\n",
        "So for this block:\n",
        "a. `digit` array holds all the images. \n",
        "b. `targets` array holds the correspnding labels.\n",
        "\n",
        "Your task is to:\n",
        "1. Choose the numbers you wish to classify.\n",
        "2. Using a condition on the `target` array, find which indices hold the digits of your choice. Take the top 300 indices from this selection for both digits.\n",
        "3. Create the new dataset by concatenating image arrays both digits and label arrays for both digits."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hints\n",
        "# 1. `np.where` might help you\n",
        "# 2. you can use indexing after np.where like: x = np.where(condition)[0][start:end]\n",
        "# 3. Fancy indexing allows you to use something like x in above example to select elements from arrays"
      ],
      "metadata": {
        "id": "eA1Jh5P2c0cT",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "number_a =  # TODO choose your digit\n",
        "number_b =  # TODO choose your digit\n",
        "\n",
        "digit_a_indexes = # select 300 indices for number a\n",
        "digit_b_indexes = # select 300 indices for number b\n",
        "\n",
        "# replace <> with correct arrays\n",
        "targets = np.concatenate((<labels of digit a>, <labels of digit b>)) \n",
        "print(targets.shape[0]) # must be 600\n",
        "images = np.concatenate((<images of digit a>, <images of digit b>))\n",
        "print(images.shape[0]) # must be 600\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, targets, test_size=0.1, random_state=42)\n",
        "\n",
        "for index, image in enumerate(X_train[:10]):\n",
        "    plt.subplot(1, 10, index + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k4gRLl2MaUR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t7_IoDhah2b"
      },
      "source": [
        "# 1. Feature Extraction\n",
        "\n",
        "You will create 2 feature extractors based on the numbers you choose. Feature extractors are mathematical operations that map an image (represented either as a 2D array or a 1D vector) into an alternative mathematical representation, such as a single scalar.  In this assignment, our feature extractors will be two functions which take in an image and output a single float. Please use mean or total intensity and one feature extractor metric, and then please create a second feature extractor metric that quantifies image symmetry. You may change the digits you wish to classify to make this classification problem easier."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hints\n",
        "\n",
        "# 1. For symmetry take the difference between two halves of the image and take a mean of that.\n",
        "# 2. You can have symmetry about vertical or horizontal axes"
      ],
      "metadata": {
        "id": "cYYBWb1ffkK2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idT9Dhzhah2c"
      },
      "source": [
        "# please complete this function:\n",
        "def compute_features(vector):\n",
        "    image = vector.reshape(28, 28) # get back original image shape\n",
        "    def compute_feature_a(image):\n",
        "        '''compute_feature_a will compute ...'''\n",
        "\n",
        "        return # TODO\n",
        "\n",
        "    def compute_feature_b(image):\n",
        "        '''compute_feature_b will compute ...'''\n",
        "\n",
        "        return # TODO\n",
        "    \n",
        "    return compute_feature_a(image), compute_feature_b(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZUcGcnnah2i"
      },
      "source": [
        "Once you compute these two features, you can apply them to your images. Don't worry about the details of the first function below, all it does is map the `compute_features` function you wrote to each image in your `X_train` variable.\n",
        "\n",
        "Afterwards let us plot the features you've crafted to see if they can separate into two classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSvyuJdZah2i"
      },
      "source": [
        "# Apply and plot your features (you can just run this block and inspect the output)\n",
        "\n",
        "X_features = np.apply_along_axis(compute_features, 1,\n",
        "                                 X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]))\n",
        "\n",
        "X_features_a = X_features[np.where(y_train==number_a)]\n",
        "X_features_b = X_features[np.where(y_train==number_b)]\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(X_features_a[:, 0], X_features_a[:, 1], '.')\n",
        "plt.plot(X_features_b[:, 0], X_features_b[:, 1], '.')\n",
        "plt.xlabel('feature_a')\n",
        "\n",
        "plt.ylabel('feature_b')\n",
        "plt.ylim(X_features[:, 1].min(), X_features[:, 1].max()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOtC322Kah2m"
      },
      "source": [
        "# 2. Linear Classification with Pseudo Inverse\n",
        "\n",
        "`X_features` is a 2 dimensional array of features and `y_train` is our ground truth label. Find the best plane that separates these two classes using the pseudo inverse and plot it. For this problem, as discussed in class, we set the labels as `y=-1` for `number_a` and `y=1` for `number_b`.\n",
        "\n",
        "The loss $L$ we would like to minimize for each $i$ row in our matrix is.\n",
        "\n",
        "$$L  = \\frac{1}{2}\\Sigma (y^{(i)} - W^{T}x^{(i)})^{2}$$\n",
        "\n",
        "where\n",
        "\n",
        "$$x^{(i)} = \n",
        "\\begin{bmatrix}\n",
        "    feature_a \\\\\n",
        "    feature_b \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "$$W = \n",
        "\\begin{bmatrix}\n",
        "    w_1 \\\\\n",
        "    w_2 \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "\n",
        "In matrix form we convert $x^{(i)}$ into $X$ which is the number of examples we have, in our case is MNIST digit features extracted.\n",
        "\n",
        "$$X = \n",
        "\\begin{bmatrix}\n",
        "    feature_{a1} & feature_{b1} \\\\\n",
        "    feature_{a2} & feature_{b2} \\\\\n",
        "    ... & ... \\\\\n",
        "    feature_{ai} & feature_{bi} \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "\n",
        "$$L  = \\frac{1}{2}( Y-XW )^{T} (Y-XW)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFCIv7Qaah2n"
      },
      "source": [
        "### Explain\n",
        "\n",
        "Let's solve L analytically, by setting $\\frac{d}{dW}L = 0$ and solving for $W$, showing your steps along the way. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nraJeeBah2p"
      },
      "source": [
        "Step 1: $$L  = \\frac{1}{2}( Y-XW )^{T} (Y-XW)$$\n",
        "\n",
        "Step 2: $$ \\frac{d}{dW}L  = \\frac{d}{dW} \\frac{1}{2}( Y-XW )^{T} (Y-XW)$$\n",
        "\n",
        "Step 3: $$...$$\n",
        "\n",
        "(complete the remaining steps in markdown)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# Please do not forget to complete the above"
      ],
      "metadata": {
        "id": "r_xbuI17mmB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkBTfoS3ah2q"
      },
      "source": [
        "### Compute\n",
        "Going back to linear algebra, we can re-write the classification problem as $Xw = y^*$, as we did during class. Here, $X$ is our features matrix `X_features` that has the features of each data example along each row, $y^*$ is our `pseudo_y` vector, and $w$ is the unknown weights vector that we'd like to figure out.\n",
        "\n",
        "The pseudo inverse is $$(X^{T}X)^{-1}X^{T} = X^{+}$$\n",
        "\n",
        "Solving for $w$, $$w = X^{+}y^*$$\n",
        "\n",
        "To perform this computation: \n",
        "\n",
        "#### (a) create a features vector $X$ and compute its pseudo inverse. (This is the var `X_features`)\n",
        "\n",
        "#### (b) create a vector like $y^*$ to hold the labels. (Done below for you as `pseudo_y`)\n",
        "\n",
        "#### (c) find $w$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gyGK8Wpah2r"
      },
      "source": [
        "# replace labels with +1 and -1\n",
        "pseudo_y = np.copy(y_train)\n",
        "pseudo_y[y_train == number_a] = -1\n",
        "pseudo_y[y_train == number_b] = 1\n",
        "\n",
        "# Calculate w below\n",
        "# ...\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRX4MGoSah2v"
      },
      "source": [
        "### (d) To examine the result of the least squares solution under this formulation, compute the train and test error using an appropriate threshold (i.e., 0). Does your trained model generalize well to the test data? \n",
        "\n",
        "Create a function called `accuracy_metrics` which does this. Remember that you might need to apply the feature extraction to your test data and create pseudo labels for it before you calculate test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hints\n",
        "# Inside the accuracy metrics function, calculate the predicted values using features and weights\n",
        "# Set a label threshold, i.e. assign class 1 if the value is greater than some number and -1 otherwise\n",
        "# compare the predicted labels to true labels and find the PERCENTAGE of correct predictions\n",
        "# use the function for training data and testing data with correct arguments"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KI9iSTCqhU5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nqw4AaSah2w"
      },
      "source": [
        "def accuracy_metrics(features, weights, label):\n",
        "    \n",
        "    \n",
        "    return 0 # Return the % accuracy\n",
        "\n",
        "\n",
        "# When you use the function,\n",
        "# features should be your X_features\n",
        "# label should be the true label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAKH01L5ah2z"
      },
      "source": [
        "### (e) Visualize the decision boundary corresponding to your chosen threshold using the provided `visualize_model` function.  \n",
        "\n",
        "The function `visualize_model` takes in features, labels, and your calculated weights and shows a matplotlib figure. If we are using a bias term, this function assumes that the weight vector has format: `[weight0, weight1, bias]`. So bias is appended to the back of the weight vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae8MxoUWah2z"
      },
      "source": [
        "# just run this block\n",
        "import matplotlib.lines as mlines\n",
        "def newline(weight):\n",
        "    # adapted from https://stackoverflow.com/questions/36470343/how-to-draw-a-line-with-matplotlib/36479941\n",
        "    if len(weight) == 2:\n",
        "        p1 = weight[0]\n",
        "        p2 = weight[1]\n",
        "        ax = plt.gca()\n",
        "        xmin, xmax = ax.get_xbound()\n",
        "        if(p2 == 0):\n",
        "            xmin = xmax = 0\n",
        "            ymin, ymax = ax.get_ybound()\n",
        "        else:\n",
        "            ymax = -p1/p2*(xmax)\n",
        "            ymin = -p1/p2*(xmin)\n",
        "        l = mlines.Line2D([xmin,xmax], [ymin,ymax], color = \"g\", label = \"Decision\")\n",
        "        ax.add_line(l)\n",
        "       \n",
        "    elif len(weight) == 3:\n",
        "        p1 = weight[0]\n",
        "        p2 = weight[1]\n",
        "        b = weight[2]\n",
        "        ax = plt.gca()\n",
        "        xmin, xmax = ax.get_xbound()\n",
        "        if(p2 == 0):\n",
        "            xmin = xmax = b/p1\n",
        "            ymin, ymax = ax.get_ybound()\n",
        "        else:\n",
        "            ymax = -p1/p2*(xmax) - b/p2\n",
        "            ymin = -p1/p2*(xmin) - b/p2\n",
        "        l = mlines.Line2D([xmin,xmax], [ymin,ymax], color = \"g\", label = \"Decision\")\n",
        "        ax.add_line(l)\n",
        "       \n",
        "    return l\n",
        "\n",
        "def visualize_model(features, labels, weights):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    X_features_a = features[np.where(labels==-1)]\n",
        "    X_features_b = features[np.where(labels==1)]\n",
        "    plt.plot(X_features_a[:, 0], X_features_a[:, 1], '.', label = \"{}\".format(number_a))\n",
        "    plt.plot(X_features_b[:, 0], X_features_b[:, 1], '.', label = \"{}\".format(number_b))\n",
        "    plt.xlabel('feature_a')\n",
        "    plt.ylabel('feature_b')\n",
        "    plt.ylim(features[:, 1].min(), features[:, 1].max())\n",
        "    newline(weights)\n",
        "    plt.gca().legend(loc = 1)\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plug in your weight variable and run the visualization."
      ],
      "metadata": {
        "id": "cLt1UUyMktly"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIikL7IWah23"
      },
      "source": [
        "visualize_model(X_features, pseudo_y, <your weight variable>)  # should output the datapoints with the decision boundary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAHm0fCaah26"
      },
      "source": [
        "### (f) Repeat the above steps after adding in a bias term, allowing for the classification line to not pass through the origin. You can do this by augmenting the X feature matrix with an additional feature column of ones, and making the unknown weight vector one entry longer -- does performance improve?\n",
        "\n",
        "If you created your functions correctly, you shouldn't need to change them and you only need to modify `X_features`. Make sure to add this column of ones to the end of the array so that the visualization works properly and that the shape of `X_features` is now (length, 3) instead of (length, 2)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMK9x0f9ah27"
      },
      "source": [
        "# Find w and bias\n",
        "\n",
        "# Get the test and train accuracy of your model with bias\n",
        "\n",
        "# Visualize the model, you may need to change your code."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss9n3k_-ah3N"
      },
      "source": [
        "# Part II\n",
        "\n",
        "Once again, in Part II, we'll add a very small modification to your code in Part II. Here, let’s assume that this camera has a special filter in its lens that blurs the MNIST image in a special way before it is detected. Let’s model this 2D blur as a convolution with the 3x3 filter below.\n",
        "\n",
        "$$X = \n",
        "\\begin{bmatrix}\n",
        "    -1 & 0 & 1 \\\\\n",
        "    -1 & 0 & 1 \\\\\n",
        "    -1 & 0 & 1 \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "Convolve the set of MNIST images with this kernel before proceeding to compute the two features of interest as in Part I: the total image intensity, and the image symmetry. Repeat the exercise above to obtain a plot of classification performance and an average classification accuracy score. You can use the bias variable from the start for this.\n",
        "\n",
        "**Note that this classification score (in some sense) reflects what would be possible with a “computational” camera, which has a special aperture shape for enhanced image classification.**\n",
        "\n",
        " - Plot Points after feature generation\n",
        " - Linear Classification - accuracy and plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xoOUtykoS7r"
      },
      "source": [
        "# Part III\n",
        "\n",
        "In Part III, we'll examine another way in which a computational imaging system can be built. let us assume that our camera system has filters in the Fourier Plane and we can record the intensity of images after the filtering.\n",
        "\n",
        "Our feature generation will now change to reflect this imaging system. You will attempt:\n",
        " - Plot Points after feature generation\n",
        " - Linear Classification - accuracy and plots"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, write a function that generates the 2D Fourier transform of an image and plot the intensity and phase of the Fourier Transform for the input images."
      ],
      "metadata": {
        "id": "cMno0UvMpelK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.fft import fft2, fftshift, ifftshift, ifft2\n",
        "\n",
        "def FourierT(image):\n",
        "  \"Your code here\"\n",
        "\n",
        "  return\n",
        "\n",
        "for index, image in enumerate(X_train[11:21]):\n",
        "  plt.subplot(1, 10, index + 1)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(image, cmap=plt.cm.gray_r)\n",
        "plt.show()\n",
        "\n",
        "for index, image in enumerate(X_train[11:21]):\n",
        "    plt.subplot(1, 10, index + 1)\n",
        "    plt.axis('off')\n",
        "    # display the amplitude of the transform here\n",
        "plt.show()\n",
        "\n",
        "for index, image in enumerate(X_train[11:21]):\n",
        "    plt.subplot(1, 10, index + 1)\n",
        "    plt.axis('off')\n",
        "    # display the phase of the transform here)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O3JTBGuC_tfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can think of a hypothetical imaging system that can capture only the high frequency features or only the low frequency features. We can achieve this by applying a high pass filter and a low pass filter to the image. \n",
        "\n",
        "Write a function for each of them. The low pass filter should a be square of shape (10,10) and the high pass filter passes everything but this square. Return the filtered Fourier Transform magnitude for both."
      ],
      "metadata": {
        "id": "J49dsHLmG-L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hints\n",
        "# Filtering is simply taking an elementwise product with a mask in the Fourier domain.\n",
        "# For low pass filter, you can make a ones matrix of size (10,10) and pad with zeros to get the right shape\n",
        "# For high pass, do the opposite."
      ],
      "metadata": {
        "id": "a_cL0099KlmS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def high_pass(image):\n",
        "\n",
        "  return\n",
        "\n",
        "  \n",
        "def low_pass(image):\n",
        "\n",
        "  return\n",
        "\n",
        "for index, image in enumerate(X_train[11:21]):\n",
        "    plt.subplot(1, 10, index + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r)\n",
        "plt.show()\n",
        "\n",
        "for index, image in enumerate(X_train[11:21]):\n",
        "    plt.subplot(1, 10, index + 1)\n",
        "    plt.axis('off')\n",
        "    im_fft = low_pass(image)\n",
        "    plt.imshow(np.log(im_fft))\n",
        "    plt.title(\"low\")\n",
        "plt.show()\n",
        "\n",
        "for index, image in enumerate(X_train[11:21]):\n",
        "    plt.subplot(1, 10, index + 1)\n",
        "    plt.axis('off')\n",
        "    im_fft = high_pass(image)\n",
        "    plt.imshow(np.log(im_fft))\n",
        "    plt.title(\"high\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pnPtPVBuKkDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now use the mean value for the high frequency magnitudes and low frequency magnitudes as features and redo the linear classification. You can add the bias variable from the start for this."
      ],
      "metadata": {
        "id": "pBLdWgcEMTMd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1jopjH4M-08"
      },
      "source": [
        "def compute_features(vector):\n",
        "    image = vector.reshape(28, 28) # get back original image shape\n",
        "    def compute_hf_mean(image):\n",
        "        '''computes the mean magnitude of high frequency features'''\n",
        "\n",
        "        return \n",
        "\n",
        "    def compute_lf_mean(image):\n",
        "        '''computes the mean magnitude of low frequency features'''\n",
        "\n",
        "        return\n",
        "    \n",
        "    return compute_hf_mean(image), compute_lf_mean(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H5qlEyXNk6j"
      },
      "source": [
        "# Apply and plot your features (you can just run this block and inspect the output)\n",
        "\n",
        "X_f_features = np.apply_along_axis(compute_features, 1,\n",
        "                                 X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]))\n",
        "\n",
        "X_f_features_a = X_f_features[np.where(y_train==number_a)]\n",
        "X_f_features_b = X_f_features[np.where(y_train==number_b)]\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(X_f_features_a[:, 0], X_f_features_a[:, 1], '.')\n",
        "plt.plot(X_f_features_b[:, 0], X_f_features_b[:, 1], '.')\n",
        "plt.xlabel('feature_a')\n",
        "plt.ylabel('feature_b')\n",
        "plt.ylim(X_f_features[:, 1].min(), X_f_features[:, 1].max()) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}